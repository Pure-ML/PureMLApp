{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import json\n",
    "from typing import List, Sequence, Dict, Any\n",
    "\n",
    "import openai\n",
    "from toolhouse import Toolhouse\n",
    "from llama_index.core.tools import FunctionTool, BaseTool\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.core.workflow import Workflow, step, Context, StartEvent, StopEvent\n",
    "from llama_index.core import (\n",
    "    ServiceContext, SimpleDirectoryReader, Document, StorageContext, Prompt, GPTVectorStoreIndex,\n",
    "    VectorStoreIndex, SummaryIndex\n",
    ")\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.types import ChatMessage, MessageRole\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops (useful in Jupyter notebooks)\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Set your API keys (ensure these are correctly set in your environment)\n",
    "# from config_keys import set_keys\n",
    "# set_keys()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Retrieve API keys from environment variables\n",
    "# openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "# pinecone_api_key = os.environ[\"PINECONE_API_KEY\"]\n",
    "# toolhouse_api_key = os.environ[\"TOOLHOUSE_API_KEY\"]\n",
    "# tavily_api_key = os.environ[\"TAVILY_API_KEY\"]\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "toolhouse_api_key = os.getenv(\"TOOLHOUSE_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Configure OpenAI\n",
    "openai.api_key = openai_api_key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index_name = \"llamaindex-ragathon-demo-index-v4700\"\n",
    "\n",
    "pinecone_index = pc.Index(index_name)\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "pdf_directory = \"./car_pdfs\"\n",
    "pdf_files = [os.path.join(pdf_directory, f) for f in os.listdir(pdf_directory) if f.endswith('.pdf')]\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\"  # Options: \"markdown\", \"text\"\n",
    ")\n",
    "file_extractor = {\".pdf\": parser}\n",
    "pdf_documents = SimpleDirectoryReader(input_files=pdf_files, file_extractor=file_extractor).load_data()\n",
    "print(f\"Number of PDF documents loaded: {len(pdf_documents)}\")\n",
    "index = VectorStoreIndex.from_documents(pdf_documents, storage_context=storage_context)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine,\n",
    "    name=\"car_data_batch_1\",\n",
    "    description=\"Use this RAG engine tool to search the ingested PDFs for missing car attributes.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "from llama_index.tools.tavily_research import TavilyToolSpec\n",
    "\n",
    "def web_search_tavily(col: str, context_data: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Function to invoke Tavily search engine and fill the missing car data for the given column.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a query string that describes the missing information and car context\n",
    "        query = f\"Find the '{col}' of a car with the following details: {context_data}. Return only the '{col}'.\"\n",
    "\n",
    "        # Initialize Tavily tool\n",
    "        tavily_tool = TavilyToolSpec(api_key=tavily_api_key)\n",
    "\n",
    "        # Use Tavily to search for the information\n",
    "        search_result = tavily_tool.search(query, max_results=1)\n",
    "        return search_result[0]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in Tavily search: {e}\")\n",
    "        return \"Information not found.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_tool = FunctionTool.from_defaults(\n",
    "    fn=web_search_tavily,\n",
    "    name=\"web_search\",\n",
    "    description=(\n",
    "        \"Use this tool to perform a web search to assist you in the filling of missing car attributes.\"\n",
    "        \"Requires 'col' (the column name) and 'context_data' (non-null data from the row) as parameters.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "examples = [\n",
    "    {\n",
    "        'id': 0,\n",
    "        'brand': 'MINI',\n",
    "        'model': 'Cooper S Base',\n",
    "        'model_year': 2007,\n",
    "        'milage': 213000,\n",
    "        'fuel_type': 'Gasoline',\n",
    "        'engine': '172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel',\n",
    "        'transmission': 'A/T',\n",
    "        'ext_col': 'Yellow',\n",
    "        'int_col': 'Gray',\n",
    "        'accident': 'None reported',\n",
    "        'price': 4200\n",
    "    },\n",
    "    {\n",
    "        'id': 1,\n",
    "        'brand': 'Lincoln',\n",
    "        'model': 'LS V8',\n",
    "        'model_year': 2002,\n",
    "        'milage': 143250,\n",
    "        'fuel_type': 'Gasoline',\n",
    "        'engine': '252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel',\n",
    "        'transmission': 'A/T',\n",
    "        'ext_col': 'Silver',\n",
    "        'int_col': 'Beige',\n",
    "        'accident': 'At least 1 accident or damage reported',\n",
    "        'price': 4999\n",
    "    },\n",
    "    {\n",
    "        'id': 2,\n",
    "        'brand': 'Chevrolet',\n",
    "        'model': 'Silverado 2500 LT',\n",
    "        'model_year': 2002,\n",
    "        'milage': 136731,\n",
    "        'fuel_type': 'E85 Flex Fuel',\n",
    "        'engine': '320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capability',\n",
    "        'transmission': 'A/T',\n",
    "        'ext_col': 'Blue',\n",
    "        'int_col': 'Gray',\n",
    "        'accident': 'None reported',\n",
    "        'price': 13900\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "system_prompt_agent = (\n",
    "    \"You are an AI assistant that helps fill in missing car data in a dataset. \"\n",
    "    \"For each missing value, analyze the row-level context provided. \"\n",
    "    \"Determine which tool to find the missing value and invoke the necessary tool and pass the parameters as defined.\"\n",
    "    \"Provide only the requested value without additional text. \"\n",
    "    \"Provide the answer following the format in the examples below.\\n\\n\"\n",
    "    f\"Here are some examples:\\n{examples}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [rag_tool, web_search_tool],\n",
    "    llm=Settings.llm,\n",
    "    verbose=True,\n",
    "    system_prompt=system_prompt_agent,\n",
    "    memory=None\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "dataset_with_nulls = pd.read_csv('null20.csv')\n",
    "print(\"Dataset with null values:\")\n",
    "print(dataset_with_nulls.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complete_null_values(agent, dataset: pd.DataFrame, demo_max=20):\n",
    "    \"\"\"Fill null values in specific columns by calling the agent.\"\"\"\n",
    "    for i, row in dataset.head(demo_max).iterrows():\n",
    "        for col in dataset.columns:\n",
    "            if pd.isnull(row[col]):  # If the value is null in this specific column\n",
    "                # Reset the agent's chat history before each new query\n",
    "                agent.reset()\n",
    "\n",
    "                # Extract non-null values from the row as context data\n",
    "                context_data = row.dropna().to_dict()\n",
    "\n",
    "                # Construct the prompt for the agent\n",
    "                prompt = (\n",
    "                    f\"Given the following examples: {examples}, \"\n",
    "                    f\"and using the information available, \"\n",
    "                    f\"provide a clear and concise {col} value for the car using the following details from the current row: {context_data}. \"\n",
    "                    f\"Use the row context and the tools available to you to infer the correct {col}. \"\n",
    "                    f\"Both tools require the 'col' parameter which is the following string: {col} and the 'context_data' parameter which is the following dictionary: {context_data}. \"\n",
    "                    f\"Do not return 'I don't know' unless absolutely necessary. If information is missing, make a well-reasoned guess based on the context provided. \"\n",
    "                    f\"Return only the {col} value and nothing else. Ensure it follows the format seen in the examples provided.\"\n",
    "                )\n",
    "\n",
    "                print(\"Full prompt:\", prompt)\n",
    "\n",
    "                # Call the agent synchronously\n",
    "                result = agent.chat(prompt)\n",
    "\n",
    "                # Fill the specific column with the response\n",
    "                dataset.at[i, col] = result\n",
    "\n",
    "                print(f\"Filling column '{col}' for row {i} with: {result}\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_dataset = complete_null_values(agent, dataset_with_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_dataset.to_csv('completed_car_data.csv', index=False)\n",
    "print(\"Completed dataset:\")\n",
    "print(completed_dataset.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
