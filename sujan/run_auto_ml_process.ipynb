{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoWvNu+EdkUTCtgnZsE4Me",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pure-ML/PureMLApp/blob/main/sujan/run_auto_ml_process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install FLAML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS6tqSJIeVoY",
        "outputId": "e8769244-db71-416e-c0db-1e51de566be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: FLAML in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: NumPy>=1.17 in /usr/local/lib/python3.10/dist-packages (from FLAML) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXgjW-ZBeIau",
        "outputId": "847e6877-dd37-400c-f094-270327a7af7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 20:49:01] {1728} INFO - task = regression\n",
            "[flaml.automl.logger: 10-13 20:49:01] {1739} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 10-13 20:49:01] {1838} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl.logger: 10-13 20:49:01] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd']\n",
            "[flaml.automl.logger: 10-13 20:49:01] {2258} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:02] {2393} INFO - Estimated sufficient time budget=9839s. Estimated necessary time budget=70s.\n",
            "[flaml.automl.logger: 10-13 20:49:02] {2442} INFO -  at 1.1s,\testimator lgbm's best error=0.9354,\tbest estimator lgbm's best error=0.9354\n",
            "[flaml.automl.logger: 10-13 20:49:02] {2258} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:02] {2442} INFO -  at 1.3s,\testimator lgbm's best error=0.9354,\tbest estimator lgbm's best error=0.9354\n",
            "[flaml.automl.logger: 10-13 20:49:02] {2258} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:02] {2442} INFO -  at 1.8s,\testimator lgbm's best error=0.9354,\tbest estimator lgbm's best error=0.9354\n",
            "[flaml.automl.logger: 10-13 20:49:02] {2258} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:03] {2442} INFO -  at 2.4s,\testimator lgbm's best error=0.9354,\tbest estimator lgbm's best error=0.9354\n",
            "[flaml.automl.logger: 10-13 20:49:03] {2258} INFO - iteration 4, current learner sgd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 20:49:04] {2442} INFO -  at 3.2s,\testimator sgd's best error=1.7058,\tbest estimator lgbm's best error=0.9354\n",
            "[flaml.automl.logger: 10-13 20:49:04] {2258} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:05] {2442} INFO -  at 4.4s,\testimator lgbm's best error=0.9354,\tbest estimator lgbm's best error=0.9354\n",
            "[flaml.automl.logger: 10-13 20:49:05] {2258} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:06] {2442} INFO -  at 5.0s,\testimator lgbm's best error=0.9339,\tbest estimator lgbm's best error=0.9339\n",
            "[flaml.automl.logger: 10-13 20:49:06] {2258} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:07] {2442} INFO -  at 6.6s,\testimator lgbm's best error=0.9339,\tbest estimator lgbm's best error=0.9339\n",
            "[flaml.automl.logger: 10-13 20:49:07] {2258} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:08] {2442} INFO -  at 7.4s,\testimator lgbm's best error=0.9339,\tbest estimator lgbm's best error=0.9339\n",
            "[flaml.automl.logger: 10-13 20:49:08] {2258} INFO - iteration 9, current learner sgd\n",
            "[flaml.automl.logger: 10-13 20:49:09] {2442} INFO -  at 8.2s,\testimator sgd's best error=1.6944,\tbest estimator lgbm's best error=0.9339\n",
            "[flaml.automl.logger: 10-13 20:49:09] {2258} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:10] {2442} INFO -  at 9.2s,\testimator xgboost's best error=0.9339,\tbest estimator lgbm's best error=0.9339\n",
            "[flaml.automl.logger: 10-13 20:49:10] {2258} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:11] {2442} INFO -  at 10.7s,\testimator xgboost's best error=0.9339,\tbest estimator lgbm's best error=0.9339\n",
            "[flaml.automl.logger: 10-13 20:49:11] {2258} INFO - iteration 12, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:13] {2442} INFO -  at 12.3s,\testimator xgboost's best error=0.9339,\tbest estimator lgbm's best error=0.9339\n",
            "[flaml.automl.logger: 10-13 20:49:13] {2258} INFO - iteration 13, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:13] {2442} INFO -  at 12.7s,\testimator extra_tree's best error=0.9227,\tbest estimator extra_tree's best error=0.9227\n",
            "[flaml.automl.logger: 10-13 20:49:13] {2258} INFO - iteration 14, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:14] {2442} INFO -  at 13.5s,\testimator extra_tree's best error=0.9227,\tbest estimator extra_tree's best error=0.9227\n",
            "[flaml.automl.logger: 10-13 20:49:14] {2258} INFO - iteration 15, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:15] {2442} INFO -  at 14.1s,\testimator extra_tree's best error=0.9227,\tbest estimator extra_tree's best error=0.9227\n",
            "[flaml.automl.logger: 10-13 20:49:15] {2258} INFO - iteration 16, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:15] {2442} INFO -  at 14.6s,\testimator extra_tree's best error=0.9227,\tbest estimator extra_tree's best error=0.9227\n",
            "[flaml.automl.logger: 10-13 20:49:15] {2258} INFO - iteration 17, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:16] {2442} INFO -  at 15.1s,\testimator extra_tree's best error=0.9062,\tbest estimator extra_tree's best error=0.9062\n",
            "[flaml.automl.logger: 10-13 20:49:16] {2685} INFO - retrain extra_tree for 0.1s\n",
            "[flaml.automl.logger: 10-13 20:49:16] {2688} INFO - retrained model: ExtraTreesRegressor(max_leaf_nodes=4, n_estimators=4, n_jobs=-1,\n",
            "                    random_state=12032022)\n",
            "[flaml.automl.logger: 10-13 20:49:16] {1985} INFO - fit succeeded\n",
            "[flaml.automl.logger: 10-13 20:49:16] {1986} INFO - Time taken to find the best model: 15.133791446685791\n",
            "Best Model: extra_tree\n",
            "Best Hyperparameters: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 4}\n",
            "R-squared on test data: 0.1834182936313673\n",
            "Mean Squared Error on test data: 1761946755.0756168\n",
            "Mean Absolute Error on test data: 21104.03048816235\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from flaml import AutoML\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset and take the first 1000 rows\n",
        "data = pd.read_csv('/content/sample_data/base_dataset.csv').head(1000)\n",
        "\n",
        "# Separate the features and the target variable\n",
        "X = data.drop(columns=['price'])  # Drop the target column from the features\n",
        "y = data['price']  # Set the target column\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up FLAML AutoML\n",
        "automl = AutoML()\n",
        "automl_settings = {\n",
        "    \"time_budget\": 15,  # Set the time budget in seconds\n",
        "    \"metric\": 'r2',  # For regression tasks, R-squared is often a good metric\n",
        "    \"task\": 'regression',  # Specify that this is a regression task\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = automl.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error\n",
        "mae = mean_absolute_error(y_test, y_pred)  # Mean Absolute Error\n",
        "r2 = r2_score(y_test, y_pred)  # R-squared Score\n",
        "\n",
        "# Optional: Print the best model\n",
        "print(\"Best Model:\", automl.best_estimator)\n",
        "print(\"Best Hyperparameters:\", automl.best_config)\n",
        "# print(\"Best R-squared on validation data:\", automl.best_loss)\n",
        "\n",
        "print(\"R-squared on test data:\", r2)\n",
        "print(\"Mean Squared Error on test data:\", mse)\n",
        "print(\"Mean Absolute Error on test data:\", mae)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/null_agent_output_dataset.csv').head(1000)\n",
        "\n",
        "X = data.drop(columns=['price'])  # Drop the target column from the features\n",
        "y = data['price']  # Set the target column\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up FLAML AutoML\n",
        "automl = AutoML()\n",
        "automl_settings = {\n",
        "    \"time_budget\": 15,  # Set the time budget in seconds\n",
        "    \"metric\": 'r2',  # For regression tasks, R-squared is often a good metric\n",
        "    \"task\": 'regression',  # Specify that this is a regression task\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = automl.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error\n",
        "mae = mean_absolute_error(y_test, y_pred)  # Mean Absolute Error\n",
        "r2 = r2_score(y_test, y_pred)  # R-squared Score\n",
        "\n",
        "# Optional: Print the best model\n",
        "print(\"Best Model:\", automl.best_estimator)\n",
        "print(\"Best Hyperparameters:\", automl.best_config)\n",
        "# print(\"Best R-squared on validation data:\", automl.best_loss)\n",
        "\n",
        "print(\"R-squared on test data:\", r2)\n",
        "print(\"Mean Squared Error on test data:\", mse)\n",
        "print(\"Mean Absolute Error on test data:\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y5wdY5DfFCD",
        "outputId": "bbbac1b2-e22c-4418-906b-e28b85b0dc9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 20:49:16] {1728} INFO - task = regression\n",
            "[flaml.automl.logger: 10-13 20:49:16] {1739} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 10-13 20:49:16] {1838} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl.logger: 10-13 20:49:16] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd']\n",
            "[flaml.automl.logger: 10-13 20:49:16] {2258} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:17] {2393} INFO - Estimated sufficient time budget=4414s. Estimated necessary time budget=32s.\n",
            "[flaml.automl.logger: 10-13 20:49:17] {2442} INFO -  at 0.6s,\testimator lgbm's best error=0.9708,\tbest estimator lgbm's best error=0.9708\n",
            "[flaml.automl.logger: 10-13 20:49:17] {2258} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:17] {2442} INFO -  at 0.9s,\testimator lgbm's best error=0.9708,\tbest estimator lgbm's best error=0.9708\n",
            "[flaml.automl.logger: 10-13 20:49:17] {2258} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:17] {2442} INFO -  at 1.1s,\testimator lgbm's best error=0.9708,\tbest estimator lgbm's best error=0.9708\n",
            "[flaml.automl.logger: 10-13 20:49:17] {2258} INFO - iteration 3, current learner sgd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 20:49:18] {2442} INFO -  at 2.0s,\testimator sgd's best error=1.7056,\tbest estimator lgbm's best error=0.9708\n",
            "[flaml.automl.logger: 10-13 20:49:18] {2258} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:19] {2442} INFO -  at 2.6s,\testimator lgbm's best error=0.9708,\tbest estimator lgbm's best error=0.9708\n",
            "[flaml.automl.logger: 10-13 20:49:19] {2258} INFO - iteration 5, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:20] {2442} INFO -  at 4.2s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.9708\n",
            "[flaml.automl.logger: 10-13 20:49:20] {2258} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:21] {2442} INFO -  at 5.5s,\testimator lgbm's best error=0.9708,\tbest estimator lgbm's best error=0.9708\n",
            "[flaml.automl.logger: 10-13 20:49:21] {2258} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:22] {2442} INFO -  at 6.6s,\testimator lgbm's best error=0.9708,\tbest estimator lgbm's best error=0.9708\n",
            "[flaml.automl.logger: 10-13 20:49:23] {2258} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:23] {2442} INFO -  at 6.9s,\testimator lgbm's best error=0.9525,\tbest estimator lgbm's best error=0.9525\n",
            "[flaml.automl.logger: 10-13 20:49:23] {2258} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:23] {2442} INFO -  at 7.4s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.9525\n",
            "[flaml.automl.logger: 10-13 20:49:23] {2258} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:25] {2442} INFO -  at 9.4s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.9525\n",
            "[flaml.automl.logger: 10-13 20:49:25] {2258} INFO - iteration 11, current learner sgd\n",
            "[flaml.automl.logger: 10-13 20:49:26] {2442} INFO -  at 10.2s,\testimator sgd's best error=1.6940,\tbest estimator lgbm's best error=0.9525\n",
            "[flaml.automl.logger: 10-13 20:49:26] {2258} INFO - iteration 12, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:27] {2442} INFO -  at 10.7s,\testimator extra_tree's best error=1.0820,\tbest estimator lgbm's best error=0.9525\n",
            "[flaml.automl.logger: 10-13 20:49:27] {2258} INFO - iteration 13, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:27] {2442} INFO -  at 11.2s,\testimator extra_tree's best error=1.0820,\tbest estimator lgbm's best error=0.9525\n",
            "[flaml.automl.logger: 10-13 20:49:27] {2258} INFO - iteration 14, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:28] {2442} INFO -  at 11.7s,\testimator extra_tree's best error=1.0820,\tbest estimator lgbm's best error=0.9525\n",
            "[flaml.automl.logger: 10-13 20:49:28] {2258} INFO - iteration 15, current learner rf\n",
            "[flaml.automl.logger: 10-13 20:49:28] {2442} INFO -  at 12.1s,\testimator rf's best error=6.1285,\tbest estimator lgbm's best error=0.9525\n",
            "[flaml.automl.logger: 10-13 20:49:28] {2258} INFO - iteration 16, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:29] {2442} INFO -  at 12.6s,\testimator extra_tree's best error=1.0820,\tbest estimator lgbm's best error=0.9525\n",
            "[flaml.automl.logger: 10-13 20:49:29] {2258} INFO - iteration 17, current learner rf\n",
            "[flaml.automl.logger: 10-13 20:49:29] {2442} INFO -  at 13.3s,\testimator rf's best error=6.1285,\tbest estimator lgbm's best error=0.9525\n",
            "[flaml.automl.logger: 10-13 20:49:29] {2258} INFO - iteration 18, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:30] {2442} INFO -  at 14.0s,\testimator extra_tree's best error=1.0820,\tbest estimator lgbm's best error=0.9525\n",
            "[flaml.automl.logger: 10-13 20:49:30] {2258} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:31] {2442} INFO -  at 14.6s,\testimator lgbm's best error=0.9413,\tbest estimator lgbm's best error=0.9413\n",
            "[flaml.automl.logger: 10-13 20:49:31] {2258} INFO - iteration 20, current learner rf\n",
            "[flaml.automl.logger: 10-13 20:49:31] {2442} INFO -  at 14.9s,\testimator rf's best error=1.5441,\tbest estimator lgbm's best error=0.9413\n",
            "[flaml.automl.logger: 10-13 20:49:31] {2258} INFO - iteration 21, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-13 20:49:31] {2442} INFO -  at 15.3s,\testimator xgb_limitdepth's best error=0.9758,\tbest estimator lgbm's best error=0.9413\n",
            "[flaml.automl.logger: 10-13 20:49:31] {2685} INFO - retrain lgbm for 0.1s\n",
            "[flaml.automl.logger: 10-13 20:49:31] {2688} INFO - retrained model: LGBMRegressor(learning_rate=0.17316392416249965, max_bin=511,\n",
            "              min_child_samples=45, n_estimators=1, n_jobs=-1, num_leaves=5,\n",
            "              reg_alpha=0.016375861714883106, reg_lambda=81.1632422599273,\n",
            "              verbose=-1)\n",
            "[flaml.automl.logger: 10-13 20:49:31] {1985} INFO - fit succeeded\n",
            "[flaml.automl.logger: 10-13 20:49:31] {1986} INFO - Time taken to find the best model: 14.56958270072937\n",
            "Best Model: lgbm\n",
            "Best Hyperparameters: {'n_estimators': 4, 'num_leaves': 5, 'min_child_samples': 45, 'learning_rate': 0.17316392416249965, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.016375861714883106, 'reg_lambda': 81.1632422599273}\n",
            "R-squared on test data: 0.0872401237679542\n",
            "Mean Squared Error on test data: 1969471382.4072165\n",
            "Mean Absolute Error on test data: 24742.12971946052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JAao5ZuNg3Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/column_agent_output.csv').head(1000)\n",
        "\n",
        "X = data.drop(columns=['price'])  # Drop the target column from the features\n",
        "y = data['price']  # Set the target column\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up FLAML AutoML\n",
        "automl = AutoML()\n",
        "automl_settings = {\n",
        "    \"time_budget\": 15,  # Set the time budget in seconds\n",
        "    \"metric\": 'r2',  # For regression tasks, R-squared is often a good metric\n",
        "    \"task\": 'regression',  # Specify that this is a regression task\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = automl.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error\n",
        "mae = mean_absolute_error(y_test, y_pred)  # Mean Absolute Error\n",
        "r2 = r2_score(y_test, y_pred)  # R-squared Score\n",
        "\n",
        "# Optional: Print the best model\n",
        "print(\"Best Model:\", automl.best_estimator)\n",
        "print(\"Best Hyperparameters:\", automl.best_config)\n",
        "# print(\"Best R-squared on validation data:\", automl.best_loss)\n",
        "\n",
        "print(\"R-squared on test data:\", r2)\n",
        "print(\"Mean Squared Error on test data:\", mse)\n",
        "print(\"Mean Absolute Error on test data:\", mae)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-kxN7ung1QV",
        "outputId": "d03ec7da-c755-4ee0-f15e-d95fc83468bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 20:49:32] {1728} INFO - task = regression\n",
            "[flaml.automl.logger: 10-13 20:49:32] {1739} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 10-13 20:49:32] {1838} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl.logger: 10-13 20:49:32] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd']\n",
            "[flaml.automl.logger: 10-13 20:49:32] {2258} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:34] {2393} INFO - Estimated sufficient time budget=22523s. Estimated necessary time budget=161s.\n",
            "[flaml.automl.logger: 10-13 20:49:34] {2442} INFO -  at 2.5s,\testimator lgbm's best error=0.9702,\tbest estimator lgbm's best error=0.9702\n",
            "[flaml.automl.logger: 10-13 20:49:34] {2258} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:36] {2442} INFO -  at 3.9s,\testimator lgbm's best error=0.9702,\tbest estimator lgbm's best error=0.9702\n",
            "[flaml.automl.logger: 10-13 20:49:36] {2258} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:36] {2442} INFO -  at 4.4s,\testimator lgbm's best error=0.9702,\tbest estimator lgbm's best error=0.9702\n",
            "[flaml.automl.logger: 10-13 20:49:36] {2258} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:37] {2442} INFO -  at 4.7s,\testimator lgbm's best error=0.9702,\tbest estimator lgbm's best error=0.9702\n",
            "[flaml.automl.logger: 10-13 20:49:37] {2258} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:37] {2442} INFO -  at 5.4s,\testimator lgbm's best error=0.9702,\tbest estimator lgbm's best error=0.9702\n",
            "[flaml.automl.logger: 10-13 20:49:37] {2258} INFO - iteration 5, current learner sgd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 20:49:38] {2442} INFO -  at 6.5s,\testimator sgd's best error=1.7056,\tbest estimator lgbm's best error=0.9702\n",
            "[flaml.automl.logger: 10-13 20:49:38] {2258} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:39] {2442} INFO -  at 7.4s,\testimator lgbm's best error=0.9702,\tbest estimator lgbm's best error=0.9702\n",
            "[flaml.automl.logger: 10-13 20:49:39] {2258} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:39] {2442} INFO -  at 7.6s,\testimator lgbm's best error=0.9517,\tbest estimator lgbm's best error=0.9517\n",
            "[flaml.automl.logger: 10-13 20:49:39] {2258} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2442} INFO -  at 7.7s,\testimator lgbm's best error=0.9274,\tbest estimator lgbm's best error=0.9274\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2258} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2442} INFO -  at 7.8s,\testimator lgbm's best error=0.9274,\tbest estimator lgbm's best error=0.9274\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2258} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2442} INFO -  at 7.9s,\testimator lgbm's best error=0.8975,\tbest estimator lgbm's best error=0.8975\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2258} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2442} INFO -  at 8.1s,\testimator lgbm's best error=0.8975,\tbest estimator lgbm's best error=0.8975\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2258} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2442} INFO -  at 8.2s,\testimator lgbm's best error=0.8975,\tbest estimator lgbm's best error=0.8975\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2258} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2442} INFO -  at 8.3s,\testimator lgbm's best error=0.8975,\tbest estimator lgbm's best error=0.8975\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2258} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2442} INFO -  at 8.5s,\testimator lgbm's best error=0.8853,\tbest estimator lgbm's best error=0.8853\n",
            "[flaml.automl.logger: 10-13 20:49:40] {2258} INFO - iteration 15, current learner sgd\n",
            "[flaml.automl.logger: 10-13 20:49:41] {2442} INFO -  at 9.0s,\testimator sgd's best error=1.6940,\tbest estimator lgbm's best error=0.8853\n",
            "[flaml.automl.logger: 10-13 20:49:41] {2258} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:41] {2442} INFO -  at 9.1s,\testimator lgbm's best error=0.8853,\tbest estimator lgbm's best error=0.8853\n",
            "[flaml.automl.logger: 10-13 20:49:41] {2258} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:41] {2442} INFO -  at 9.2s,\testimator lgbm's best error=0.8853,\tbest estimator lgbm's best error=0.8853\n",
            "[flaml.automl.logger: 10-13 20:49:41] {2258} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:41] {2442} INFO -  at 9.3s,\testimator lgbm's best error=0.8853,\tbest estimator lgbm's best error=0.8853\n",
            "[flaml.automl.logger: 10-13 20:49:41] {2258} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:41] {2442} INFO -  at 9.5s,\testimator lgbm's best error=0.8853,\tbest estimator lgbm's best error=0.8853\n",
            "[flaml.automl.logger: 10-13 20:49:41] {2258} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:41] {2442} INFO -  at 9.6s,\testimator lgbm's best error=0.8853,\tbest estimator lgbm's best error=0.8853\n",
            "[flaml.automl.logger: 10-13 20:49:41] {2258} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2442} INFO -  at 9.8s,\testimator lgbm's best error=0.8853,\tbest estimator lgbm's best error=0.8853\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2258} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2442} INFO -  at 9.9s,\testimator lgbm's best error=0.8853,\tbest estimator lgbm's best error=0.8853\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2258} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2442} INFO -  at 10.0s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2258} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2442} INFO -  at 10.1s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2258} INFO - iteration 25, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2442} INFO -  at 10.3s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2258} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2442} INFO -  at 10.4s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2258} INFO - iteration 27, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2442} INFO -  at 10.5s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:42] {2258} INFO - iteration 28, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2442} INFO -  at 10.7s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2258} INFO - iteration 29, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2442} INFO -  at 10.8s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2258} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2442} INFO -  at 10.9s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2258} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2442} INFO -  at 11.1s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2258} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2442} INFO -  at 11.2s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2258} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2442} INFO -  at 11.3s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2258} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2442} INFO -  at 11.5s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2258} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2442} INFO -  at 11.6s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:43] {2258} INFO - iteration 36, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:44] {2442} INFO -  at 11.7s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:44] {2258} INFO - iteration 37, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:44] {2442} INFO -  at 11.9s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:44] {2258} INFO - iteration 38, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:44] {2442} INFO -  at 12.0s,\testimator lgbm's best error=0.8803,\tbest estimator lgbm's best error=0.8803\n",
            "[flaml.automl.logger: 10-13 20:49:44] {2258} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:44] {2442} INFO -  at 12.2s,\testimator lgbm's best error=0.8764,\tbest estimator lgbm's best error=0.8764\n",
            "[flaml.automl.logger: 10-13 20:49:44] {2258} INFO - iteration 40, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:44] {2442} INFO -  at 12.3s,\testimator lgbm's best error=0.8764,\tbest estimator lgbm's best error=0.8764\n",
            "[flaml.automl.logger: 10-13 20:49:44] {2258} INFO - iteration 41, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:44] {2442} INFO -  at 12.5s,\testimator lgbm's best error=0.8764,\tbest estimator lgbm's best error=0.8764\n",
            "[flaml.automl.logger: 10-13 20:49:44] {2258} INFO - iteration 42, current learner sgd\n",
            "[flaml.automl.logger: 10-13 20:49:45] {2442} INFO -  at 12.9s,\testimator sgd's best error=1.3721,\tbest estimator lgbm's best error=0.8764\n",
            "[flaml.automl.logger: 10-13 20:49:45] {2258} INFO - iteration 43, current learner sgd\n",
            "[flaml.automl.logger: 10-13 20:49:45] {2442} INFO -  at 13.1s,\testimator sgd's best error=1.3721,\tbest estimator lgbm's best error=0.8764\n",
            "[flaml.automl.logger: 10-13 20:49:45] {2258} INFO - iteration 44, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:45] {2442} INFO -  at 13.3s,\testimator lgbm's best error=0.8764,\tbest estimator lgbm's best error=0.8764\n",
            "[flaml.automl.logger: 10-13 20:49:45] {2258} INFO - iteration 45, current learner sgd\n",
            "[flaml.automl.logger: 10-13 20:49:46] {2442} INFO -  at 13.8s,\testimator sgd's best error=1.0587,\tbest estimator lgbm's best error=0.8764\n",
            "[flaml.automl.logger: 10-13 20:49:46] {2258} INFO - iteration 46, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:46] {2442} INFO -  at 13.9s,\testimator lgbm's best error=0.8764,\tbest estimator lgbm's best error=0.8764\n",
            "[flaml.automl.logger: 10-13 20:49:46] {2258} INFO - iteration 47, current learner sgd\n",
            "[flaml.automl.logger: 10-13 20:49:46] {2442} INFO -  at 14.2s,\testimator sgd's best error=1.0587,\tbest estimator lgbm's best error=0.8764\n",
            "[flaml.automl.logger: 10-13 20:49:46] {2258} INFO - iteration 48, current learner sgd\n",
            "[flaml.automl.logger: 10-13 20:49:47] {2442} INFO -  at 15.0s,\testimator sgd's best error=1.0587,\tbest estimator lgbm's best error=0.8764\n",
            "[flaml.automl.logger: 10-13 20:49:47] {2258} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:47] {2442} INFO -  at 15.0s,\testimator xgboost's best error=0.9878,\tbest estimator lgbm's best error=0.8764\n",
            "[flaml.automl.logger: 10-13 20:49:47] {2685} INFO - retrain lgbm for 0.0s\n",
            "[flaml.automl.logger: 10-13 20:49:47] {2688} INFO - retrained model: LGBMRegressor(colsample_bytree=0.9829462620318432,\n",
            "              learning_rate=0.4889062961714401, max_bin=1023,\n",
            "              min_child_samples=35, n_estimators=1, n_jobs=-1, num_leaves=4,\n",
            "              reg_alpha=0.0016621255356914734, reg_lambda=1024.0, verbose=-1)\n",
            "[flaml.automl.logger: 10-13 20:49:47] {1985} INFO - fit succeeded\n",
            "[flaml.automl.logger: 10-13 20:49:47] {1986} INFO - Time taken to find the best model: 12.158809185028076\n",
            "Best Model: lgbm\n",
            "Best Hyperparameters: {'n_estimators': 13, 'num_leaves': 4, 'min_child_samples': 35, 'learning_rate': 0.4889062961714401, 'log_max_bin': 10, 'colsample_bytree': 0.9829462620318432, 'reg_alpha': 0.0016621255356914734, 'reg_lambda': 1024.0}\n",
            "R-squared on test data: 0.11693687021378163\n",
            "Mean Squared Error on test data: 1905394406.8535807\n",
            "Mean Absolute Error on test data: 23406.5448363085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/pavel_agent_output.csv').head(1000)\n",
        "\n",
        "X = data.drop(columns=['price'])  # Drop the target column from the features\n",
        "y = data['price']  # Set the target column\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up FLAML AutoML\n",
        "automl = AutoML()\n",
        "automl_settings = {\n",
        "    \"time_budget\": 15,  # Set the time budget in seconds\n",
        "    \"metric\": 'r2',  # For regression tasks, R-squared is often a good metric\n",
        "    \"task\": 'regression',  # Specify that this is a regression task\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = automl.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error\n",
        "mae = mean_absolute_error(y_test, y_pred)  # Mean Absolute Error\n",
        "r2 = r2_score(y_test, y_pred)  # R-squared Score\n",
        "\n",
        "# Optional: Print the best model\n",
        "print(\"Best Model:\", automl.best_estimator)\n",
        "print(\"Best Hyperparameters:\", automl.best_config)\n",
        "# print(\"Best R-squared on validation data:\", automl.best_loss)\n",
        "\n",
        "print(\"R-squared on test data:\", r2)\n",
        "print(\"Mean Squared Error on test data:\", mse)\n",
        "print(\"Mean Absolute Error on test data:\", mae)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARkoR7OVin3V",
        "outputId": "67bec35b-45ed-4449-8a04-0814dcaa99d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 20:49:47] {1728} INFO - task = regression\n",
            "[flaml.automl.logger: 10-13 20:49:47] {1739} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 10-13 20:49:47] {1838} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl.logger: 10-13 20:49:47] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd']\n",
            "[flaml.automl.logger: 10-13 20:49:47] {2258} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:48] {2393} INFO - Estimated sufficient time budget=4326s. Estimated necessary time budget=31s.\n",
            "[flaml.automl.logger: 10-13 20:49:48] {2442} INFO -  at 0.5s,\testimator lgbm's best error=0.9705,\tbest estimator lgbm's best error=0.9705\n",
            "[flaml.automl.logger: 10-13 20:49:48] {2258} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:48] {2442} INFO -  at 0.8s,\testimator lgbm's best error=0.9705,\tbest estimator lgbm's best error=0.9705\n",
            "[flaml.automl.logger: 10-13 20:49:48] {2258} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:48] {2442} INFO -  at 1.0s,\testimator lgbm's best error=0.9705,\tbest estimator lgbm's best error=0.9705\n",
            "[flaml.automl.logger: 10-13 20:49:48] {2258} INFO - iteration 3, current learner sgd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 20:49:49] {2442} INFO -  at 1.6s,\testimator sgd's best error=1.7056,\tbest estimator lgbm's best error=0.9705\n",
            "[flaml.automl.logger: 10-13 20:49:49] {2258} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:49] {2442} INFO -  at 2.4s,\testimator lgbm's best error=0.9705,\tbest estimator lgbm's best error=0.9705\n",
            "[flaml.automl.logger: 10-13 20:49:49] {2258} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2442} INFO -  at 2.6s,\testimator lgbm's best error=0.9705,\tbest estimator lgbm's best error=0.9705\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2258} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2442} INFO -  at 2.7s,\testimator lgbm's best error=0.9705,\tbest estimator lgbm's best error=0.9705\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2258} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2442} INFO -  at 2.8s,\testimator lgbm's best error=0.9519,\tbest estimator lgbm's best error=0.9519\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2258} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2442} INFO -  at 3.0s,\testimator lgbm's best error=0.9288,\tbest estimator lgbm's best error=0.9288\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2258} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2442} INFO -  at 3.1s,\testimator lgbm's best error=0.9288,\tbest estimator lgbm's best error=0.9288\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2258} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2442} INFO -  at 3.2s,\testimator lgbm's best error=0.8808,\tbest estimator lgbm's best error=0.8808\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2258} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2442} INFO -  at 3.3s,\testimator lgbm's best error=0.8808,\tbest estimator lgbm's best error=0.8808\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2258} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2442} INFO -  at 3.5s,\testimator lgbm's best error=0.8808,\tbest estimator lgbm's best error=0.8808\n",
            "[flaml.automl.logger: 10-13 20:49:50] {2258} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:51] {2442} INFO -  at 3.6s,\testimator lgbm's best error=0.8808,\tbest estimator lgbm's best error=0.8808\n",
            "[flaml.automl.logger: 10-13 20:49:51] {2258} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:51] {2442} INFO -  at 3.7s,\testimator lgbm's best error=0.8643,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:51] {2258} INFO - iteration 15, current learner sgd\n",
            "[flaml.automl.logger: 10-13 20:49:51] {2442} INFO -  at 4.0s,\testimator sgd's best error=1.6940,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:51] {2258} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:51] {2442} INFO -  at 4.1s,\testimator lgbm's best error=0.8643,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:51] {2258} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:51] {2442} INFO -  at 4.3s,\testimator lgbm's best error=0.8643,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:51] {2258} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:51] {2442} INFO -  at 4.4s,\testimator lgbm's best error=0.8643,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:51] {2258} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2442} INFO -  at 4.5s,\testimator lgbm's best error=0.8643,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2258} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2442} INFO -  at 4.7s,\testimator lgbm's best error=0.8643,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2258} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2442} INFO -  at 4.8s,\testimator lgbm's best error=0.8643,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2258} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2442} INFO -  at 4.9s,\testimator lgbm's best error=0.8643,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2258} INFO - iteration 23, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2442} INFO -  at 5.0s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2258} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2442} INFO -  at 5.2s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2258} INFO - iteration 25, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2442} INFO -  at 5.4s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:52] {2258} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:53] {2442} INFO -  at 5.6s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:53] {2258} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:53] {2442} INFO -  at 5.8s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:53] {2258} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:53] {2442} INFO -  at 6.0s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.8643\n",
            "[flaml.automl.logger: 10-13 20:49:53] {2258} INFO - iteration 29, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:53] {2442} INFO -  at 6.1s,\testimator lgbm's best error=0.8582,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:53] {2258} INFO - iteration 30, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:53] {2442} INFO -  at 6.4s,\testimator extra_tree's best error=1.0820,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:53] {2258} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:54] {2442} INFO -  at 6.6s,\testimator lgbm's best error=0.8582,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:54] {2258} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:55] {2442} INFO -  at 7.6s,\testimator lgbm's best error=0.8582,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:55] {2258} INFO - iteration 33, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:55] {2442} INFO -  at 7.8s,\testimator extra_tree's best error=1.0820,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:55] {2258} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:55] {2442} INFO -  at 8.1s,\testimator lgbm's best error=0.8582,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:55] {2258} INFO - iteration 35, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:55] {2442} INFO -  at 8.5s,\testimator extra_tree's best error=1.0820,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:55] {2258} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:56] {2442} INFO -  at 8.8s,\testimator extra_tree's best error=1.0820,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:56] {2258} INFO - iteration 37, current learner rf\n",
            "[flaml.automl.logger: 10-13 20:49:56] {2442} INFO -  at 9.1s,\testimator rf's best error=5.7947,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:56] {2258} INFO - iteration 38, current learner rf\n",
            "[flaml.automl.logger: 10-13 20:49:56] {2442} INFO -  at 9.3s,\testimator rf's best error=5.7947,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:56] {2258} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:57] {2442} INFO -  at 9.5s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:57] {2258} INFO - iteration 40, current learner rf\n",
            "[flaml.automl.logger: 10-13 20:49:57] {2442} INFO -  at 9.8s,\testimator rf's best error=5.7947,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:57] {2258} INFO - iteration 41, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:57] {2442} INFO -  at 10.1s,\testimator extra_tree's best error=1.0820,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:57] {2258} INFO - iteration 42, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:57] {2442} INFO -  at 10.3s,\testimator extra_tree's best error=1.0820,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:57] {2258} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:57] {2442} INFO -  at 10.4s,\testimator lgbm's best error=0.8582,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:57] {2258} INFO - iteration 44, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:58] {2442} INFO -  at 10.6s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:58] {2258} INFO - iteration 45, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:58] {2442} INFO -  at 10.8s,\testimator extra_tree's best error=0.9978,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:58] {2258} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:58] {2442} INFO -  at 11.0s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:58] {2258} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:58] {2442} INFO -  at 11.1s,\testimator lgbm's best error=0.8582,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:58] {2258} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:49:58] {2442} INFO -  at 11.3s,\testimator xgboost's best error=0.9234,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:58] {2258} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:58] {2442} INFO -  at 11.4s,\testimator lgbm's best error=0.8582,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:58] {2258} INFO - iteration 50, current learner rf\n",
            "[flaml.automl.logger: 10-13 20:49:59] {2442} INFO -  at 11.7s,\testimator rf's best error=5.7947,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:59] {2258} INFO - iteration 51, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:49:59] {2442} INFO -  at 11.9s,\testimator extra_tree's best error=0.9978,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:59] {2258} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:59] {2442} INFO -  at 12.0s,\testimator lgbm's best error=0.8582,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:59] {2258} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:59] {2442} INFO -  at 12.2s,\testimator lgbm's best error=0.8582,\tbest estimator lgbm's best error=0.8582\n",
            "[flaml.automl.logger: 10-13 20:49:59] {2258} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:59] {2442} INFO -  at 12.3s,\testimator lgbm's best error=0.8556,\tbest estimator lgbm's best error=0.8556\n",
            "[flaml.automl.logger: 10-13 20:49:59] {2258} INFO - iteration 55, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:49:59] {2442} INFO -  at 12.4s,\testimator lgbm's best error=0.8556,\tbest estimator lgbm's best error=0.8556\n",
            "[flaml.automl.logger: 10-13 20:49:59] {2258} INFO - iteration 56, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:50:00] {2442} INFO -  at 12.6s,\testimator xgboost's best error=0.9234,\tbest estimator lgbm's best error=0.8556\n",
            "[flaml.automl.logger: 10-13 20:50:00] {2258} INFO - iteration 57, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:00] {2442} INFO -  at 12.9s,\testimator lgbm's best error=0.8556,\tbest estimator lgbm's best error=0.8556\n",
            "[flaml.automl.logger: 10-13 20:50:00] {2258} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:01] {2442} INFO -  at 13.6s,\testimator lgbm's best error=0.8556,\tbest estimator lgbm's best error=0.8556\n",
            "[flaml.automl.logger: 10-13 20:50:01] {2258} INFO - iteration 59, current learner rf\n",
            "[flaml.automl.logger: 10-13 20:50:01] {2442} INFO -  at 14.0s,\testimator rf's best error=5.4568,\tbest estimator lgbm's best error=0.8556\n",
            "[flaml.automl.logger: 10-13 20:50:01] {2258} INFO - iteration 60, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:01] {2442} INFO -  at 14.3s,\testimator lgbm's best error=0.8556,\tbest estimator lgbm's best error=0.8556\n",
            "[flaml.automl.logger: 10-13 20:50:01] {2258} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:50:02] {2442} INFO -  at 14.7s,\testimator xgboost's best error=0.8909,\tbest estimator lgbm's best error=0.8556\n",
            "[flaml.automl.logger: 10-13 20:50:02] {2258} INFO - iteration 62, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:02] {2442} INFO -  at 15.2s,\testimator lgbm's best error=0.8556,\tbest estimator lgbm's best error=0.8556\n",
            "[flaml.automl.logger: 10-13 20:50:02] {2685} INFO - retrain lgbm for 0.1s\n",
            "[flaml.automl.logger: 10-13 20:50:02] {2688} INFO - retrained model: LGBMRegressor(learning_rate=1.0, max_bin=1023, min_child_samples=19,\n",
            "              n_estimators=1, n_jobs=-1, num_leaves=8,\n",
            "              reg_alpha=0.04797939077620568, reg_lambda=1024.0, verbose=-1)\n",
            "[flaml.automl.logger: 10-13 20:50:02] {1985} INFO - fit succeeded\n",
            "[flaml.automl.logger: 10-13 20:50:02] {1986} INFO - Time taken to find the best model: 12.315348625183105\n",
            "Best Model: lgbm\n",
            "Best Hyperparameters: {'n_estimators': 11, 'num_leaves': 8, 'min_child_samples': 19, 'learning_rate': 1.0, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.04797939077620568, 'reg_lambda': 1024.0}\n",
            "R-squared on test data: 0.08697151600986963\n",
            "Mean Squared Error on test data: 1970050960.1323285\n",
            "Mean Absolute Error on test data: 24083.14689757435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "null_agent_output=pd.read_csv(\"/content/sample_data/null_agent_output_dataset.csv\")\n",
        "column_agent_output=pd.read_csv(\"/content/sample_data/column_agent_output.csv\")\n",
        "pavel_agent_output=pd.read_csv(\"/content/sample_data/pavel_agent_output.csv\")\n",
        "\n",
        "\n",
        "merged_df_step1 = null_agent_output.combine_first(column_agent_output)\n",
        "\n",
        "final_merged_df = merged_df_step1.combine_first(pavel_agent_output)\n",
        "\n",
        "final_merged_df_filled = final_merged_df.fillna('')\n",
        "\n",
        "final_merged_df_filled.head()\n",
        "\n",
        "output_path = '/content/sample_data/datasmith.csv'\n",
        "\n",
        "final_merged_df_filled.to_csv(output_path, index=False)"
      ],
      "metadata": {
        "id": "THQA9ptTnltr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/datasmith.csv').head(1000)\n",
        "\n",
        "X = data.drop(columns=['price'])  # Drop the target column from the features\n",
        "y = data['price']  # Set the target column\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up FLAML AutoML\n",
        "automl = AutoML()\n",
        "automl_settings = {\n",
        "    \"time_budget\": 15,  # Set the time budget in seconds\n",
        "    \"metric\": 'r2',  # For regression tasks, R-squared is often a good metric\n",
        "    \"task\": 'regression',  # Specify that this is a regression task\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = automl.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error\n",
        "mae = mean_absolute_error(y_test, y_pred)  # Mean Absolute Error\n",
        "r2 = r2_score(y_test, y_pred)  # R-squared Score\n",
        "\n",
        "# Optional: Print the best model\n",
        "print(\"Best Model:\", automl.best_estimator)\n",
        "print(\"Best Hyperparameters:\", automl.best_config)\n",
        "# print(\"Best R-squared on validation data:\", automl.best_loss)\n",
        "\n",
        "print(\"R-squared on test data:\", r2)\n",
        "print(\"Mean Squared Error on test data:\", mse)\n",
        "print(\"Mean Absolute Error on test data:\", mae)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se-sOhcPo2B2",
        "outputId": "b51b0683-1ec6-49b7-d2e9-eee346e18c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 20:50:03] {1728} INFO - task = regression\n",
            "[flaml.automl.logger: 10-13 20:50:03] {1739} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 10-13 20:50:03] {1838} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl.logger: 10-13 20:50:03] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd']\n",
            "[flaml.automl.logger: 10-13 20:50:03] {2258} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:04] {2393} INFO - Estimated sufficient time budget=1226s. Estimated necessary time budget=9s.\n",
            "[flaml.automl.logger: 10-13 20:50:04] {2442} INFO -  at 0.2s,\testimator lgbm's best error=0.9707,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 20:50:04] {2258} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:04] {2442} INFO -  at 0.3s,\testimator lgbm's best error=0.9707,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 20:50:04] {2258} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:04] {2442} INFO -  at 0.4s,\testimator lgbm's best error=0.9707,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 20:50:04] {2258} INFO - iteration 3, current learner sgd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 20:50:04] {2442} INFO -  at 0.9s,\testimator sgd's best error=1.7056,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 20:50:04] {2258} INFO - iteration 4, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:50:04] {2442} INFO -  at 1.1s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 20:50:05] {2258} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:05] {2442} INFO -  at 1.3s,\testimator lgbm's best error=0.9707,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 20:50:05] {2258} INFO - iteration 6, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:50:05] {2442} INFO -  at 1.5s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 20:50:05] {2258} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:05] {2442} INFO -  at 1.6s,\testimator lgbm's best error=0.9707,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 20:50:05] {2258} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:05] {2442} INFO -  at 1.8s,\testimator lgbm's best error=0.9707,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 20:50:05] {2258} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:50:05] {2442} INFO -  at 2.0s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 20:50:05] {2258} INFO - iteration 10, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:50:06] {2442} INFO -  at 2.2s,\testimator extra_tree's best error=0.9499,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:06] {2258} INFO - iteration 11, current learner rf\n",
            "[flaml.automl.logger: 10-13 20:50:06] {2442} INFO -  at 2.5s,\testimator rf's best error=6.1285,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:06] {2258} INFO - iteration 12, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:50:06] {2442} INFO -  at 2.7s,\testimator xgboost's best error=0.9955,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:06] {2258} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:50:06] {2442} INFO -  at 3.0s,\testimator xgboost's best error=0.9955,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:06] {2258} INFO - iteration 14, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:50:07] {2442} INFO -  at 3.2s,\testimator extra_tree's best error=0.9499,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:07] {2258} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:50:07] {2442} INFO -  at 3.4s,\testimator xgboost's best error=0.9955,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:07] {2258} INFO - iteration 16, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:50:07] {2442} INFO -  at 3.7s,\testimator extra_tree's best error=0.9499,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:07] {2258} INFO - iteration 17, current learner rf\n",
            "[flaml.automl.logger: 10-13 20:50:07] {2442} INFO -  at 4.0s,\testimator rf's best error=6.1285,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:07] {2258} INFO - iteration 18, current learner sgd\n",
            "[flaml.automl.logger: 10-13 20:50:08] {2442} INFO -  at 4.5s,\testimator sgd's best error=1.6940,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:08] {2258} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:08] {2442} INFO -  at 4.6s,\testimator lgbm's best error=0.9525,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:08] {2258} INFO - iteration 20, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:50:08] {2442} INFO -  at 4.9s,\testimator extra_tree's best error=0.9499,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:08] {2258} INFO - iteration 21, current learner rf\n",
            "[flaml.automl.logger: 10-13 20:50:09] {2442} INFO -  at 5.2s,\testimator rf's best error=6.1285,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:09] {2258} INFO - iteration 22, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:50:09] {2442} INFO -  at 5.4s,\testimator xgboost's best error=0.9955,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 20:50:09] {2258} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:09] {2442} INFO -  at 5.6s,\testimator lgbm's best error=0.9277,\tbest estimator lgbm's best error=0.9277\n",
            "[flaml.automl.logger: 10-13 20:50:09] {2258} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:09] {2442} INFO -  at 5.9s,\testimator lgbm's best error=0.9277,\tbest estimator lgbm's best error=0.9277\n",
            "[flaml.automl.logger: 10-13 20:50:09] {2258} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:50:10] {2442} INFO -  at 6.4s,\testimator extra_tree's best error=0.9499,\tbest estimator lgbm's best error=0.9277\n",
            "[flaml.automl.logger: 10-13 20:50:10] {2258} INFO - iteration 26, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:50:10] {2442} INFO -  at 6.9s,\testimator extra_tree's best error=0.9499,\tbest estimator lgbm's best error=0.9277\n",
            "[flaml.automl.logger: 10-13 20:50:10] {2258} INFO - iteration 27, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:11] {2442} INFO -  at 7.2s,\testimator lgbm's best error=0.8926,\tbest estimator lgbm's best error=0.8926\n",
            "[flaml.automl.logger: 10-13 20:50:11] {2258} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:50:12] {2442} INFO -  at 8.4s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.8926\n",
            "[flaml.automl.logger: 10-13 20:50:12] {2258} INFO - iteration 29, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:50:12] {2442} INFO -  at 8.9s,\testimator extra_tree's best error=0.9499,\tbest estimator lgbm's best error=0.8926\n",
            "[flaml.automl.logger: 10-13 20:50:12] {2258} INFO - iteration 30, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:50:13] {2442} INFO -  at 9.3s,\testimator extra_tree's best error=0.9499,\tbest estimator lgbm's best error=0.8926\n",
            "[flaml.automl.logger: 10-13 20:50:13] {2258} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:13] {2442} INFO -  at 10.1s,\testimator lgbm's best error=0.8926,\tbest estimator lgbm's best error=0.8926\n",
            "[flaml.automl.logger: 10-13 20:50:13] {2258} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:15] {2442} INFO -  at 11.3s,\testimator lgbm's best error=0.8926,\tbest estimator lgbm's best error=0.8926\n",
            "[flaml.automl.logger: 10-13 20:50:15] {2258} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:15] {2442} INFO -  at 11.8s,\testimator lgbm's best error=0.8926,\tbest estimator lgbm's best error=0.8926\n",
            "[flaml.automl.logger: 10-13 20:50:15] {2258} INFO - iteration 34, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:50:16] {2442} INFO -  at 12.5s,\testimator extra_tree's best error=0.9499,\tbest estimator lgbm's best error=0.8926\n",
            "[flaml.automl.logger: 10-13 20:50:16] {2258} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 20:50:17] {2442} INFO -  at 13.6s,\testimator lgbm's best error=0.8833,\tbest estimator lgbm's best error=0.8833\n",
            "[flaml.automl.logger: 10-13 20:50:17] {2258} INFO - iteration 36, current learner rf\n",
            "[flaml.automl.logger: 10-13 20:50:18] {2442} INFO -  at 14.2s,\testimator rf's best error=6.1285,\tbest estimator lgbm's best error=0.8833\n",
            "[flaml.automl.logger: 10-13 20:50:18] {2258} INFO - iteration 37, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 20:50:18] {2442} INFO -  at 14.7s,\testimator extra_tree's best error=0.9499,\tbest estimator lgbm's best error=0.8833\n",
            "[flaml.automl.logger: 10-13 20:50:18] {2258} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 20:50:18] {2442} INFO -  at 15.1s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.8833\n",
            "[flaml.automl.logger: 10-13 20:50:19] {2685} INFO - retrain lgbm for 0.1s\n",
            "[flaml.automl.logger: 10-13 20:50:19] {2688} INFO - retrained model: LGBMRegressor(learning_rate=0.776643029407975, max_bin=1023,\n",
            "              min_child_samples=45, n_estimators=1, n_jobs=-1, num_leaves=4,\n",
            "              reg_alpha=0.0032488801357278335, reg_lambda=397.30852721370087,\n",
            "              verbose=-1)\n",
            "[flaml.automl.logger: 10-13 20:50:19] {1985} INFO - fit succeeded\n",
            "[flaml.automl.logger: 10-13 20:50:19] {1986} INFO - Time taken to find the best model: 13.574906349182129\n",
            "Best Model: lgbm\n",
            "Best Hyperparameters: {'n_estimators': 5, 'num_leaves': 4, 'min_child_samples': 45, 'learning_rate': 0.776643029407975, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0032488801357278335, 'reg_lambda': 397.30852721370087}\n",
            "R-squared on test data: 0.09210793420119334\n",
            "Mean Squared Error on test data: 1958968057.7181165\n",
            "Mean Absolute Error on test data: 24766.796664658905\n"
          ]
        }
      ]
    }
  ]
}