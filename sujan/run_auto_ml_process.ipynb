{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOci40VaXLy7aSyNY9Bszeh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pure-ML/PureMLApp/blob/main/sujan/run_auto_ml_process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install FLAML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS6tqSJIeVoY",
        "outputId": "dfaeba35-be74-4c60-eec7-4a6dcf39ec4e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: FLAML in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: NumPy>=1.17 in /usr/local/lib/python3.10/dist-packages (from FLAML) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXgjW-ZBeIau",
        "outputId": "50da28cf-7419-4e64-d440-9a9547206412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 21:30:39] {1728} INFO - task = regression\n",
            "[flaml.automl.logger: 10-13 21:30:39] {1739} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 10-13 21:30:39] {1838} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl.logger: 10-13 21:30:39] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd']\n",
            "[flaml.automl.logger: 10-13 21:30:39] {2258} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 21:30:40] {2393} INFO - Estimated sufficient time budget=8110s. Estimated necessary time budget=58s.\n",
            "[flaml.automl.logger: 10-13 21:30:40] {2442} INFO -  at 0.9s,\testimator lgbm's best error=0.9354,\tbest estimator lgbm's best error=0.9354\n",
            "[flaml.automl.logger: 10-13 21:30:40] {2258} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 21:30:41] {2442} INFO -  at 1.8s,\testimator lgbm's best error=0.9354,\tbest estimator lgbm's best error=0.9354\n",
            "[flaml.automl.logger: 10-13 21:30:41] {2258} INFO - iteration 2, current learner sgd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 21:30:42] {2442} INFO -  at 2.7s,\testimator sgd's best error=1.7058,\tbest estimator lgbm's best error=0.9354\n",
            "[flaml.automl.logger: 10-13 21:30:42] {2258} INFO - iteration 3, current learner sgd\n",
            "[flaml.automl.logger: 10-13 21:30:42] {2442} INFO -  at 3.4s,\testimator sgd's best error=1.6944,\tbest estimator lgbm's best error=0.9354\n",
            "[flaml.automl.logger: 10-13 21:30:42] {2258} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 21:30:43] {2442} INFO -  at 3.9s,\testimator lgbm's best error=0.9354,\tbest estimator lgbm's best error=0.9354\n",
            "[flaml.automl.logger: 10-13 21:30:43] {2258} INFO - iteration 5, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 21:30:43] {2442} INFO -  at 4.6s,\testimator xgboost's best error=0.9339,\tbest estimator xgboost's best error=0.9339\n",
            "[flaml.automl.logger: 10-13 21:30:43] {2258} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 21:30:44] {2442} INFO -  at 5.5s,\testimator lgbm's best error=0.9354,\tbest estimator xgboost's best error=0.9339\n",
            "[flaml.automl.logger: 10-13 21:30:44] {2258} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 21:30:46] {2442} INFO -  at 6.7s,\testimator lgbm's best error=0.9354,\tbest estimator xgboost's best error=0.9339\n",
            "[flaml.automl.logger: 10-13 21:30:46] {2258} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 21:30:47] {2442} INFO -  at 7.6s,\testimator lgbm's best error=0.9339,\tbest estimator lgbm's best error=0.9339\n",
            "[flaml.automl.logger: 10-13 21:30:47] {2258} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 21:30:49] {2442} INFO -  at 10.5s,\testimator xgboost's best error=0.9339,\tbest estimator lgbm's best error=0.9339\n",
            "[flaml.automl.logger: 10-13 21:30:49] {2258} INFO - iteration 10, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 21:30:50] {2442} INFO -  at 11.1s,\testimator extra_tree's best error=0.9227,\tbest estimator extra_tree's best error=0.9227\n",
            "[flaml.automl.logger: 10-13 21:30:50] {2258} INFO - iteration 11, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 21:30:50] {2442} INFO -  at 11.6s,\testimator extra_tree's best error=0.9227,\tbest estimator extra_tree's best error=0.9227\n",
            "[flaml.automl.logger: 10-13 21:30:50] {2258} INFO - iteration 12, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 21:30:51] {2442} INFO -  at 12.0s,\testimator extra_tree's best error=0.9227,\tbest estimator extra_tree's best error=0.9227\n",
            "[flaml.automl.logger: 10-13 21:30:51] {2258} INFO - iteration 13, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 21:30:51] {2442} INFO -  at 12.6s,\testimator extra_tree's best error=0.9227,\tbest estimator extra_tree's best error=0.9227\n",
            "[flaml.automl.logger: 10-13 21:30:51] {2258} INFO - iteration 14, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 21:30:52] {2442} INFO -  at 13.0s,\testimator extra_tree's best error=0.9150,\tbest estimator extra_tree's best error=0.9150\n",
            "[flaml.automl.logger: 10-13 21:30:52] {2258} INFO - iteration 15, current learner rf\n",
            "[flaml.automl.logger: 10-13 21:30:53] {2442} INFO -  at 13.7s,\testimator rf's best error=1.3508,\tbest estimator extra_tree's best error=0.9150\n",
            "[flaml.automl.logger: 10-13 21:30:53] {2258} INFO - iteration 16, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 21:30:54] {2442} INFO -  at 15.2s,\testimator xgboost's best error=0.9339,\tbest estimator extra_tree's best error=0.9150\n",
            "[flaml.automl.logger: 10-13 21:30:54] {2685} INFO - retrain extra_tree for 0.1s\n",
            "[flaml.automl.logger: 10-13 21:30:54] {2688} INFO - retrained model: ExtraTreesRegressor(max_leaf_nodes=4, n_estimators=5, n_jobs=-1,\n",
            "                    random_state=12032022)\n",
            "[flaml.automl.logger: 10-13 21:30:54] {1985} INFO - fit succeeded\n",
            "[flaml.automl.logger: 10-13 21:30:54] {1986} INFO - Time taken to find the best model: 12.984360218048096\n",
            "Best Model: extra_tree\n",
            "Best Hyperparameters: {'n_estimators': 5, 'max_features': 1.0, 'max_leaves': 4}\n",
            "R-squared on test data: 0.20170380505040963\n",
            "Mean Squared Error on test data: 1722491918.825421\n",
            "Mean Absolute Error on test data: 19869.36555912011\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from flaml import AutoML\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset and take the first 1000 rows\n",
        "data = pd.read_csv('/content/sample_data/base_dataset.csv').head(1000)\n",
        "\n",
        "# Separate the features and the target variable\n",
        "X = data.drop(columns=['price'])  # Drop the target column from the features\n",
        "y = data['price']  # Set the target column\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up FLAML AutoML\n",
        "automl = AutoML()\n",
        "automl_settings = {\n",
        "    \"time_budget\": 15,  # Set the time budget in seconds\n",
        "    \"metric\": 'r2',  # For regression tasks, R-squared is often a good metric\n",
        "    \"task\": 'regression',  # Specify that this is a regression task\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = automl.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error\n",
        "mae = mean_absolute_error(y_test, y_pred)  # Mean Absolute Error\n",
        "r2 = r2_score(y_test, y_pred)  # R-squared Score\n",
        "\n",
        "# Optional: Print the best model\n",
        "print(\"Best Model:\", automl.best_estimator)\n",
        "print(\"Best Hyperparameters:\", automl.best_config)\n",
        "# print(\"Best R-squared on validation data:\", automl.best_loss)\n",
        "\n",
        "print(\"R-squared on test data:\", r2)\n",
        "print(\"Mean Squared Error on test data:\", mse)\n",
        "print(\"Mean Absolute Error on test data:\", mae)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JAao5ZuNg3Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_agent_output=pd.read_csv(\"/content/sample_data/null_agent_output_dataset.csv\")\n",
        "\n",
        "column_agent_output=pd.read_csv(\"/content/sample_data/column_agent_output.csv\")\n",
        "column_agent_output.drop(columns=['body_type', 'luxury_vehicle'])\n",
        "column_agent_output.to_csv(\"/content/sample_data/column_agent_output.csv\", index=False)\n",
        "\n",
        "pavel_agent_output=pd.read_csv(\"/content/sample_data/pavel_agent_output_new.csv\")\n",
        "\n",
        "merged_df_step1 = null_agent_output.combine_first(column_agent_output)\n",
        "\n",
        "final_merged_df = merged_df_step1.combine_first(pavel_agent_output)\n",
        "\n",
        "final_merged_df_filled = final_merged_df.fillna('')\n",
        "\n",
        "final_merged_df_filled.head()\n",
        "\n",
        "output_path = '/content/sample_data/datasmith.csv'\n",
        "\n",
        "final_merged_df_filled.to_csv(output_path, index=False)"
      ],
      "metadata": {
        "id": "THQA9ptTnltr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/datasmith.csv').head(1000)\n",
        "\n",
        "X = data.drop(columns=['price'])  # Drop the target column from the features\n",
        "y = data['price']  # Set the target column\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up FLAML AutoML\n",
        "automl = AutoML()\n",
        "automl_settings = {\n",
        "    \"time_budget\": 15,  # Set the time budget in seconds\n",
        "    \"metric\": 'r2',  # For regression tasks, R-squared is often a good metric\n",
        "    \"task\": 'regression',  # Specify that this is a regression task\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = automl.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error\n",
        "mae = mean_absolute_error(y_test, y_pred)  # Mean Absolute Error\n",
        "r2 = r2_score(y_test, y_pred)  # R-squared Score\n",
        "\n",
        "# Optional: Print the best model\n",
        "print(\"Best Model:\", automl.best_estimator)\n",
        "print(\"Best Hyperparameters:\", automl.best_config)\n",
        "# print(\"Best R-squared on validation data:\", automl.best_loss)\n",
        "\n",
        "print(\"R-squared on test data:\", r2)\n",
        "print(\"Mean Squared Error on test data:\", mse)\n",
        "print(\"Mean Absolute Error on test data:\", mae)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se-sOhcPo2B2",
        "outputId": "987623d6-317e-4078-8a32-df6df2d3b3ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 21:30:57] {1728} INFO - task = regression\n",
            "[flaml.automl.logger: 10-13 21:30:57] {1739} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 10-13 21:30:57] {1838} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl.logger: 10-13 21:30:57] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd']\n",
            "[flaml.automl.logger: 10-13 21:30:57] {2258} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 21:30:57] {2393} INFO - Estimated sufficient time budget=4801s. Estimated necessary time budget=34s.\n",
            "[flaml.automl.logger: 10-13 21:30:57] {2442} INFO -  at 0.6s,\testimator lgbm's best error=0.9707,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 21:30:57] {2258} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 21:30:58] {2442} INFO -  at 0.9s,\testimator lgbm's best error=0.9707,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 21:30:58] {2258} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 21:31:00] {2442} INFO -  at 3.2s,\testimator lgbm's best error=0.9707,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 21:31:00] {2258} INFO - iteration 3, current learner sgd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 10-13 21:31:02] {2442} INFO -  at 4.7s,\testimator sgd's best error=1.7056,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 21:31:02] {2258} INFO - iteration 4, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 21:31:04] {2442} INFO -  at 7.0s,\testimator xgboost's best error=0.9955,\tbest estimator lgbm's best error=0.9707\n",
            "[flaml.automl.logger: 10-13 21:31:04] {2258} INFO - iteration 5, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 21:31:04] {2442} INFO -  at 7.5s,\testimator extra_tree's best error=0.9499,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:04] {2258} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 10-13 21:31:05] {2442} INFO -  at 8.1s,\testimator lgbm's best error=0.9707,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:05] {2258} INFO - iteration 7, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 21:31:05] {2442} INFO -  at 8.6s,\testimator extra_tree's best error=0.9499,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:05] {2258} INFO - iteration 8, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 21:31:07] {2442} INFO -  at 9.7s,\testimator xgboost's best error=0.9955,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:07] {2258} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 21:31:08] {2442} INFO -  at 10.8s,\testimator xgboost's best error=0.9955,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:08] {2258} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl.logger: 10-13 21:31:09] {2442} INFO -  at 11.7s,\testimator xgboost's best error=0.9955,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:09] {2258} INFO - iteration 11, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 21:31:09] {2442} INFO -  at 12.3s,\testimator extra_tree's best error=0.9499,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:09] {2258} INFO - iteration 12, current learner rf\n",
            "[flaml.automl.logger: 10-13 21:31:10] {2442} INFO -  at 13.0s,\testimator rf's best error=6.1285,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:10] {2258} INFO - iteration 13, current learner rf\n",
            "[flaml.automl.logger: 10-13 21:31:10] {2442} INFO -  at 13.6s,\testimator rf's best error=6.1285,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:10] {2258} INFO - iteration 14, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 21:31:11] {2442} INFO -  at 14.0s,\testimator extra_tree's best error=0.9499,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:11] {2258} INFO - iteration 15, current learner rf\n",
            "[flaml.automl.logger: 10-13 21:31:11] {2442} INFO -  at 14.6s,\testimator rf's best error=6.1285,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:11] {2258} INFO - iteration 16, current learner extra_tree\n",
            "[flaml.automl.logger: 10-13 21:31:12] {2442} INFO -  at 15.0s,\testimator extra_tree's best error=0.9499,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:12] {2258} INFO - iteration 17, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-13 21:31:12] {2442} INFO -  at 15.5s,\testimator xgb_limitdepth's best error=0.9775,\tbest estimator extra_tree's best error=0.9499\n",
            "[flaml.automl.logger: 10-13 21:31:12] {2685} INFO - retrain extra_tree for 0.1s\n",
            "[flaml.automl.logger: 10-13 21:31:12] {2688} INFO - retrained model: ExtraTreesRegressor(max_leaf_nodes=4, n_estimators=4, n_jobs=-1,\n",
            "                    random_state=12032022)\n",
            "[flaml.automl.logger: 10-13 21:31:12] {1985} INFO - fit succeeded\n",
            "[flaml.automl.logger: 10-13 21:31:12] {1986} INFO - Time taken to find the best model: 7.4772679805755615\n",
            "Best Model: extra_tree\n",
            "Best Hyperparameters: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 4}\n",
            "R-squared on test data: 0.15174926260897703\n",
            "Mean Squared Error on test data: 1830279349.3660648\n",
            "Mean Absolute Error on test data: 20810.87180910306\n"
          ]
        }
      ]
    }
  ]
}