{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import json\n",
    "from typing import List, Sequence, Dict, Any\n",
    "\n",
    "import openai\n",
    "from toolhouse import Toolhouse\n",
    "from llama_index.core.tools import FunctionTool, BaseTool\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.core.workflow import Workflow, step, Context, StartEvent, StopEvent\n",
    "from llama_index.core import (\n",
    "    ServiceContext, SimpleDirectoryReader, Document, StorageContext, Prompt, GPTVectorStoreIndex,\n",
    "    VectorStoreIndex, SummaryIndex\n",
    ")\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.types import ChatMessage, MessageRole\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops (useful in Jupyter notebooks)\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "toolhouse_api_key = os.getenv(\"TOOLHOUSE_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_third_agent = (\n",
    "    \"You are an AI assistant that helps augment car datasets by suggesting additional columns and filling them out based on the context provided. \"\n",
    "    \"Given the following car dataset, suggest 3 new columns relevant to the type of data and generate plausible values (e.g. Car body type, horsepower, country of manufacturer, is the vehicle a luxury vehicle (Yes/No), etc.)\"\n",
    "    \"Only choose new columns to add that you can provide truthful values for grounded in the context and your general knowledge.\"\n",
    "    \"Avoid adding columns where the rows would contain many None or NaN values.\"\n",
    "    \"For each row, return the suggestions and values in JSON format, with the column names as keys and lists of values corresponding to each row.\"\n",
    "    \"Ensure that the number of rows in the newly produced column matches the number of rows in the existing columns.\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the third agent\n",
    "third_agent = OpenAIAgent.from_tools(\n",
    "    llm=Settings.llm,\n",
    "    verbose=True,\n",
    "    system_prompt=system_prompt_third_agent,\n",
    "    memory=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "dataset_with_nulls = pd.read_csv('completed_car_data2.csv')\n",
    "print(\"Dataset with null values:\")\n",
    "print(dataset_with_nulls.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_and_fill_columns_by_row(agent, dataset: pd.DataFrame):\n",
    "    # Initialize dictionaries to hold new column data\n",
    "    new_column_data = {}\n",
    "\n",
    "    # Iterate through each row of the dataset\n",
    "    for index, row in dataset.iterrows():\n",
    "        # Convert the row to a dictionary\n",
    "        row_str = row.to_json()\n",
    "        \n",
    "        # Build the query string for this row\n",
    "        query_str = (\n",
    "            f\"{system_prompt_third_agent}\\n\"\n",
    "            f\"Given the following car dataset row:\\n{row_str}\\n\"\n",
    "            \"Please suggest new columns and generate plausible values for this row. \"\n",
    "            \"Return only the new columns and values in JSON format.\"\n",
    "        )\n",
    "        \n",
    "        agent.reset()  # Reset the agent to avoid residual memory effects\n",
    "        \n",
    "        try:\n",
    "            # Send the query to the agent and get the result\n",
    "            result = agent.chat(query_str).response\n",
    "            \n",
    "            # Debugging the raw response\n",
    "            print(f\"Raw agent response for row {index}: {result}\")\n",
    "            \n",
    "            # Clean the result by removing the ```json wrapper\n",
    "            if result.startswith(\"```json\"):\n",
    "                result = result.strip(\"```json\").strip(\"```\")\n",
    "            \n",
    "            # Parse the result as JSON\n",
    "            row_new_columns = json.loads(result)\n",
    "            \n",
    "            # Append the new column values to the corresponding row\n",
    "            for column, value in row_new_columns.items():\n",
    "                if column not in new_column_data:\n",
    "                    new_column_data[column] = [None] * len(dataset)  # Initialize with None (NaN) for all rows\n",
    "                \n",
    "                # Extract the first element from the list, assuming it's a single value\n",
    "                if isinstance(value, list) and len(value) == 1:\n",
    "                    new_column_data[column][index] = value[0]  # Use the first element from the list\n",
    "                else:\n",
    "                    new_column_data[column][index] = value  # In case it's not a list, just use the value\n",
    "        \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing the agent response for row {index}: {e}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred for row {index}: {e}\")\n",
    "    \n",
    "    # Add the new columns to the dataset\n",
    "    for column, values in new_column_data.items():\n",
    "        dataset[column] = values\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_dataset_with_additional_columns = suggest_and_fill_columns_by_row(third_agent, dataset_with_nulls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_dataset_with_additional_columns.to_csv('completed_car_data_with_additional_columns.csv', index=False)\n",
    "print(\"Completed dataset with additional columns:\")\n",
    "print(completed_dataset_with_additional_columns.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
